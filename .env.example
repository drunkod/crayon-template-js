OPENROUTER_API_KEY="your_openrouter_api_key_here"
OPENROUTER_API_BASE="https://openrouter.ai/api/v1"
OPENROUTER_SITE_URL="http://localhost:4000"

# Primary model to use (will auto-fallback to others if rate-limited)
OPENROUTER_MODEL="deepseek/deepseek-r1:free"

# Google Gemini (AI Studio) via OpenAI-compatible endpoint
GEMINI_API_KEY="your_gemini_api_key_here"
GEMINI_API_BASE="https://generativelanguage.googleapis.com/v1beta/openai"

# Default Gemini model when using AI Studio (can be overridden)
# Note: "gpt-4.1-mini" is an alias for a Gemini model under the OpenAI-compatible endpoint.
GEMINI_MODEL="gpt-4.1-mini"

# Which real AI provider to use when NOT in mock mode: "openrouter" or "gemini"
AI_PROVIDER="openrouter"
NEXT_PUBLIC_AI_PROVIDER="openrouter"

# Set to "true" to use mock data (no internet required)
NEXT_PUBLIC_USE_MOCK_WEATHER="true"

# Set to "true" to use mock OpenRouter (completely offline)
NEXT_PUBLIC_USE_MOCK_OPENROUTER="true"

NEXT_PUBLIC_DEBUG_MODE="true"
